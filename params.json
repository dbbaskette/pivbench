{"name":"PivBench","tagline":"Automation of the TPC-DS benchmark for Pivotal HAWQ.","body":"# pivbench\r\n###Pivotal HAWQ TPC-DS Benchmarking Tool\r\n--\r\n\r\nAutomation of the TPC-DS benchmark for Pivotal HAWQ.\r\n\r\nThe application is broken into functions that are run independently.  Since some modules require feedback just after executions, it is recommended you run these with nohup python pivbench.py.   Enter the information that is required, hit CTRL-Z and then bg 1 to background the process.   Alternatively, you can pass the clear-text password(s) required via the command line options (this would only be recommended in test environments)\r\n\r\n* **gen (Generate)** - This takes the size and HDFS target of the benchmark data and leverages MapReduce to create the datafiles.   It's a patched version of the generator included with Hortonworks Hive-Bench.  It also changes the Replication factor to 2 for the directory to save capacity.  \r\n* **load** - This module creates the HAWQ tables and PXF External tables and moves the Raw - Pipe Delimited data into HAWQ.  For the larger fact tables, non-partitioned tables (labeled as _nopart) as created to speed the data load.\r\n* **part (Partition)** - Takes number of partitions as a parameter and creates Partitioned versions of the larger fact tables with the _nopart name removed.  It then does a insert into X select * from Y to load the tables.  This method allows for easier modification in the event new partition sizes are needed.\r\n* **analyze** - This module will analyze all the fact and diminsion tables.\r\n*  **query** - Runs any single query, or all 99 TPC-DS queries against the database and records the elapsed times of each.  It also clears the buffers and cache on all cluster nodes before every query executes.   You can use --num to run 1 or more queries, or use --set to predefine a set of queries.   Current options are 'all', and 'hive' which either run all queries, or just the hive compatible ones.\r\n```\r\n2015-05-30 10:33:15,539 INFO Executing HAWQ Queries\r\n2015-05-30 10:33:15,540 INFO Running all Queries\r\n2015-05-30 10:33:15,539 INFO ---------------------------------\r\n2015-05-30 10:40:19,821 INFO Query: query_55   Execution Time(s): xxx.xx  Rows Returned: 100\r\n2015-05-30 10:45:00,443 INFO Query: query_30   Execution Time(s): xxx.xx  Rows Returned: 100\r\n2015-05-30 11:14:15,389 INFO Query: query_79   Execution Time(s): xxx.xx  Rows Returned: 100\r\n2015-05-30 11:18:12,482 INFO Query: query_92   Execution Time(s): xxx.xx  Rows Returned: 1\r\n2015-05-30 11:25:39,422 INFO Query: query_85   Execution Time(s): xxx.xx  Rows Returned: 71\r\n```\r\n\r\nPre-Reqs\r\n--------\r\nyum -y install python-devel\r\nyum -y install postgresql-devel\r\n","google":"","note":"Don't delete this file! It's used internally to help with page regeneration."}